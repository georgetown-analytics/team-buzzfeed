{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('may_june_july.csv', delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>impressions</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>29316</td>\n",
       "      <td>Giant man with tiny dog alert! The Mountain Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17180</td>\n",
       "      <td>FYI: Ice cream sandwiches &amp;gt; all other sandw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3474</td>\n",
       "      <td>\"My mama always said you can tell a lot about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9027</td>\n",
       "      <td>Let's see if you're a true cheese whiz. Can Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7247</td>\n",
       "      <td>The EPA just released first-time guidelines on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq  impressions                                               tags\n",
       "0     2        29316  Giant man with tiny dog alert! The Mountain Fr...\n",
       "1     2        17180  FYI: Ice cream sandwiches &gt; all other sandw...\n",
       "2     2         3474  \"My mama always said you can tell a lot about ...\n",
       "3     2         9027  Let's see if you're a true cheese whiz. Can Yo...\n",
       "4     2         7247  The EPA just released first-time guidelines on..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all text \n",
    "df['tags'] = df['descr'] + \" \" + df[\"title\"] + \" \" + df[\"cat\"]+ \" \" + df[\"primary_kw\"]+ \" \" + df[\"tags\"] \n",
    "# Drop unneeded columns\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df.drop('pull_cc', axis=1, inplace=True)\n",
    "df.drop('cc', axis=1, inplace=True)\n",
    "df.drop('metav', axis=1, inplace=True)\n",
    "df.drop('descr', axis=1, inplace=True)\n",
    "df.drop('title', axis=1, inplace=True)\n",
    "df.drop('primary_kw', axis=1, inplace=True)\n",
    "df.drop('cat', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giant man with tiny dog alert! The Mountain Fr...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FYI: Ice cream sandwiches &amp;gt; all other sandw...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"My mama always said you can tell a lot about ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's see if you're a true cheese whiz. Can Yo...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The EPA just released first-time guidelines on...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  Log\n",
       "0  Giant man with tiny dog alert! The Mountain Fr...   15\n",
       "1  FYI: Ice cream sandwiches &gt; all other sandw...   15\n",
       "2  \"My mama always said you can tell a lot about ...   12\n",
       "3  Let's see if you're a true cheese whiz. Can Yo...   14\n",
       "4  The EPA just released first-time guidelines on...   13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NORMALIZE TO LOG DISTRIBUTION\n",
    "# Compute Log (freq*impressions/1000)\n",
    "# Add log column\n",
    "df['Log'] = df['freq']*df['impressions']\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    cv = math.log(df.iloc[i,3],2)\n",
    "    df.set_value(i,'Log',cv)\n",
    "\n",
    "# Drop unneeded column\n",
    "df.drop('freq', axis=1, inplace=True)\n",
    "df.drop('impressions', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.444149122193465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = df[\"Log\"].mean()\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2282119418494077"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_std = df[\"Log\"].std()\n",
    "data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107fb15f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"Log\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>viral</th>\n",
       "      <th>viral_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giant man with tiny dog alert! The Mountain Fr...</td>\n",
       "      <td>notviral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FYI: Ice cream sandwiches &amp;gt; all other sandw...</td>\n",
       "      <td>notviral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"My mama always said you can tell a lot about ...</td>\n",
       "      <td>notviral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's see if you're a true cheese whiz. Can Yo...</td>\n",
       "      <td>notviral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The EPA just released first-time guidelines on...</td>\n",
       "      <td>notviral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags     viral  viral_num\n",
       "0  Giant man with tiny dog alert! The Mountain Fr...  notviral          0\n",
       "1  FYI: Ice cream sandwiches &gt; all other sandw...  notviral          0\n",
       "2  \"My mama always said you can tell a lot about ...  notviral          0\n",
       "3  Let's see if you're a true cheese whiz. Can Yo...  notviral          0\n",
       "4  The EPA just released first-time guidelines on...  notviral          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Virality defined as -1 sigma from mean\n",
    "df['viral'] = np.where(df['Log']<data_mean-data_std, 'notviral', 'viral')\n",
    "df['viral_num'] = df.viral.map({'notviral':0, 'viral':1})\n",
    "df.drop('Log', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tags'].fillna('a', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>viral</th>\n",
       "      <th>viral_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>A former Stanford swimmer who sexually assault...</td>\n",
       "      <td>viral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>A former Stanford swimmer who sexually assault...</td>\n",
       "      <td>viral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>A former Stanford swimmer who sexually assault...</td>\n",
       "      <td>viral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>A definitive ranking of our dirtiest words. Th...</td>\n",
       "      <td>viral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>Don't worry, you won't need to know Chandler B...</td>\n",
       "      <td>viral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tags  viral  viral_num\n",
       "14292  A former Stanford swimmer who sexually assault...  viral          1\n",
       "14293  A former Stanford swimmer who sexually assault...  viral          1\n",
       "14294  A former Stanford swimmer who sexually assault...  viral          1\n",
       "14295  A definitive ranking of our dirtiest words. Th...  viral          1\n",
       "14296  Don't worry, you won't need to know Chandler B...  viral          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14297, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viral       11564\n",
       "notviral     2733\n",
       "Name: viral, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.viral.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14297,)\n",
      "(14297,)\n"
     ]
    }
   ],
   "source": [
    "X = df.tags\n",
    "y = df.viral_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Giant man with tiny dog alert! The Mountain Fr...\n",
       "1    FYI: Ice cream sandwiches &gt; all other sandw...\n",
       "2    \"My mama always said you can tell a lot about ...\n",
       "3    Let's see if you're a true cheese whiz. Can Yo...\n",
       "4    The EPA just released first-time guidelines on...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: viral_num, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10722,)\n",
      "(3575,)\n",
      "(10722,)\n",
      "(3575,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "# FOLLOWING CAN BE DONE IN SINGLE STEP:  X_train_dtm = vect.fit_transform(X_train)\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10722x15480 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 266669 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3575x15480 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 87915 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.83 ms, sys: 1.48 ms, total: 7.3 ms\n",
      "Wall time: 6.45 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78965034965034964"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 243,  466],\n",
       "       [ 286, 2580]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356     So much fierce, so little time. Here's What A ...\n",
       "4046     Robert Czegely has been accused of \"gross misc...\n",
       "3116     Put your JT fandom to the test. Are These Nsyn...\n",
       "1094     Hold the door. 53 Thoughts I Had Watching Seas...\n",
       "1312     Identify them all! Can You Guess The Pok mon B...\n",
       "3807     Three of the former Libyan dictator s top offi...\n",
       "2410     Tiny home, big clean. 28 Clever Ways To Deep C...\n",
       "2813     Today's characters: the Malfoys. Here Are The ...\n",
       "4781     <b>These big rocks in the desert will blow you...\n",
       "3312     For when you want a little bit of ~everything....\n",
       "10363    Yes, I want my house to smell like fairy bread...\n",
       "3895     \"Next week will see the debut of Hodor's cousi...\n",
       "4290     Some Bernie-or-Busters protested Clinton's spe...\n",
       "1401     Underrated is an UNDERstatement. It's Time To ...\n",
       "32       Michelle Carter was charged with involuntary m...\n",
       "11347    Put all those geography classes to the test. C...\n",
       "1578                                                     a\n",
       "994      <b>I got 99 problems, and Twitter spoilers are...\n",
       "857      Suck it, salad. 15 Things You'll Only Understa...\n",
       "897      Spreadin' barks and smiles! 19 Excited Dogs Ju...\n",
       "1156     Milk and cereal are a union that must not be b...\n",
       "2515     <b>From Fred Lyon's <a rel=\"nofollow\" href=\"ht...\n",
       "1365                                                     a\n",
       "2230     Talk to the hand 'cause the face ain't listeni...\n",
       "4696     Who's gonna be the ring bearer of your dreams?...\n",
       "4177     <b>Because the people deserve to know!</b> 10 ...\n",
       "3832     \"Do you know how many basic bitches would kill...\n",
       "2364     ALL THE EMOTIONS! Here's What Happens When You...\n",
       "1890     \"Thank you Nintendo!!!\" Pok mon Go Is Helping ...\n",
       "335      The joke is that it's not. Chrissy Teigen Twee...\n",
       "                               ...                        \n",
       "2977     So much drama. \"Real Housewives Of Beverly Hil...\n",
       "4165     Woodsprites are taking over underground. This ...\n",
       "5338     For when you want a little bit of ~everything....\n",
       "3796     When you start having secret meetings in the t...\n",
       "5332     You spent a hell of a lot of your time on late...\n",
       "3689     Add these ones to your brunch bucket list! 19 ...\n",
       "5930     \"Arrogant white privileged fools\" A Weatherman...\n",
       "2096     Do you like your sausages in a dog or a roll? ...\n",
       "2517     Avoca-DO make this. Honey-Lime Chicken And Avo...\n",
       "7466     <b>There&#39;s only one way to find out.</b> A...\n",
       "4107     One of them's an absolute stinker. Which Tom H...\n",
       "535      Oh, tartar sauce! 19 Faces From \"SpongeBob Squ...\n",
       "130      It's complicated AF. How Will Brexit Actually ...\n",
       "10130    French bulldogs and independent coffee shops a...\n",
       "2490     Scream if you know the answer. Only A Real Hor...\n",
       "2646     Man cannot live on trail mix alone. 29 Camping...\n",
       "597                                                      a\n",
       "5151     Mmmm, the crunch. Buttermilk-Fried Chicken Mak...\n",
       "2477     I used to compare myself to the models in maga...\n",
       "3027     Who stands out the most in a crowd? Can You Pi...\n",
       "4485     A bang for your buck. How Much Do These 9 Sex ...\n",
       "503      *Immediately opens a cat hotel.* 11 Dream Jobs...\n",
       "423      \"Secretary Clinton has won the democratic nomi...\n",
       "1687     A tale of chaos and scandal at Day One of the ...\n",
       "6153     Some people have asked for a rematch of the Ba...\n",
       "1941     This can only mean good things for everyone's ...\n",
       "7857     <b>Warning: partial nudity ahead!</b> Acclaime...\n",
       "830      All men must die. But in what order? Can You A...\n",
       "5776     Screw football, this guy should go to Hogwarts...\n",
       "2922     Who's a good customer service representative? ...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives (non-viral incorrectly classified as viral)\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7120     \"You spent some time away...\" Brace Yourselves...\n",
       "11141    Mmmmmmmmmmmmmmmm. 16 Extremely Satisfying Pict...\n",
       "12571    It wasn't. 17 Things That Will Make Every Indi...\n",
       "5558     \"You're worthy of the last French fry in the b...\n",
       "10655    Worse still, literally no one is surprised. De...\n",
       "14152    In 2016, it takes staggering ignorance to thin...\n",
       "13227    \"I am no longer okay with just being a sidekic...\n",
       "11674    The school has thousands of students, no full-...\n",
       "11436    \"I have always said, I will work after marriag...\n",
       "9034     TL;DR Poo is done with your shit. Kareena Kapo...\n",
       "13466    It seems that the key is to live anywhere othe...\n",
       "5811     A hot new type of food stack. People On Instag...\n",
       "1175     Give those old duds new life. 18 No-Sew Ways T...\n",
       "3153     The pound may be weak, but the memes are stron...\n",
       "6004     She was a better Trump than Trump. Meryl Stree...\n",
       "5640     Vote Leave, take back the status quo? Four Bre...\n",
       "11646    Pappis for puppies. 9 Pictures Of Doggies At I...\n",
       "14051    Kya re mamu! Sab changa? Yeh quiz lega kya bhe...\n",
       "8708     The golden age of TV everywhere, tbh. 13 Reaso...\n",
       "12271    That three-day stretch in March when it seems ...\n",
       "8918     Ded. These Photos Of Katrina Kaif In A Really ...\n",
       "5411     The Los Angeles County Sheriff's Department sa...\n",
       "6863     Including face masks, lingerie, dresses, and s...\n",
       "12611    #Blackdegreesmatter 38 Photos Of Black Graduat...\n",
       "8274     Meet Senator-elect Pauline Hanson. Australia's...\n",
       "3400     On Wednesday, the hashtag <a href=\"https://twi...\n",
       "10579    Stop restoring my faith in arranged marriages,...\n",
       "9864     Enrol early. Update often. Stop What You're Do...\n",
       "8157     Baroness Smith, Labour MPs, and even some Tori...\n",
       "4719     UK voters have sent a massive shock through th...\n",
       "                               ...                        \n",
       "10519    Do these policies belong to Labor, the Greens,...\n",
       "14107    You're not proud, but getting drunk in freezin...\n",
       "4331     Almost as soothing as eating it. ALMOST. This ...\n",
       "2625     Michael Sandford, a 19-year-old from Dorking i...\n",
       "12879    Could you smash 833 cans a year? Well apparent...\n",
       "12130    I'm taking the rest of the day off. Rahul Khan...\n",
       "14011    \"Fuckin eh it's bout to go downnnn.\" We Ranked...\n",
       "7137     At least five police officers were killed afte...\n",
       "10625    \"I'm bringing them home in a box\". Indigenous ...\n",
       "11239    \"G'day mates!\" Or, nah. Australian Stereotypes...\n",
       "6306     Aliens DO exist, according to the former Blink...\n",
       "575      For when you just don't have time to deal with...\n",
       "13840    Can you not? Salman Khan Compared Himself To A...\n",
       "8814     \"Freedom of speech di maa di.\" The Censor Boar...\n",
       "11983    Let the stars assign you a soulmate. Which Sou...\n",
       "10725    \"It's Levi-OH-sa, not Levi-oh-SAR.\" How Many \"...\n",
       "5806     They're all the same. 22 Pictures That Perfect...\n",
       "406      *Mixes them all together* 21 Bartenders Share ...\n",
       "9317     The PERFECT outfit... In theory. \"Dhoti Dungar...\n",
       "9454     He's hiding somewhere in these pictures... but...\n",
       "3358     Will there be a general election? Can there be...\n",
       "8572     See if you can PRUNE Mary-Kate out from the As...\n",
       "9579     \"I hope we'll be having those exchanges over t...\n",
       "5184     \"Oot and aboot.\" 21 Things You'll Never Hear A...\n",
       "6454     <b>Temper your jealousy, teachers.</b> One can...\n",
       "177      Slay, mama. 9 Stunning Eid Outfits That'll Tak...\n",
       "6704     Quit wringing my heart like a washcloth, you g...\n",
       "4036     \"You make me happier than pretzel day.\" This G...\n",
       "9875     What was wrong with me? This Is For Everyone W...\n",
       "7065     Just too good to be muggle. 17 Real Places Tha...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives (Viral incorrectly classified as non-viral)\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<b>Temper your jealousy, teachers.</b> One can always dream. 30 Epic Examples Of Inspirational Classroom Decor DIY classrooms awesome design classroom decor classroom design cool classrooms design teacher decorations teachers'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example false negative\n",
    "X_test[6454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35800925,  0.99945296,  0.99999878, ...,  0.99999947,\n",
       "        0.9999996 ,  0.98753744])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73793648012740198"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 384 ms, sys: 5.54 ms, total: 389 ms\n",
      "Wall time: 392 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77864268,  0.95959005,  0.98801846, ...,  0.98512148,\n",
       "        0.97422148,  0.74503525])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80083916083916085"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72567856991703716"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15480"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '007', '00s', '03', '06', '07', '10', '100', '100000', '100m', '101', '11', '110', '11th', '12', '125', '129', '13', '14', '140', '143', '15', '150', '1500', '151', '16', '160', '16_new_food', '16th', '17', '172', '177', '1789', '17th', '18', '182', '18311', '18th', '19', '1938922913', '1955', '1960s', '1964', '1966', '1969', '1970s', '1972', '1980', '1980s']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zachary', 'zack', 'zackary', 'zafar', 'zafn', 'zaful', 'zag', 'zakia', 'zambia', 'zanada', 'zara', 'zaveri', 'zayn', 'zbych', 'zealand', 'zebra', 'zelda', 'zemeckis', 'zen', 'zendaya', 'zero', 'zesty', 'zeus', 'zhang', 'zhao', 'zig', 'zika', 'zinger', 'zip', 'zit', 'ziva', 'zo', 'zodiac', 'zodiacquiz', 'zoe', 'zoey', 'zombies', 'zone', 'zoo', 'zoodles', 'zooey', 'zookeeper', 'zoom', 'zootopia', 'zoren', 'zucchini', 'zuchinni', 'zuckerberg', 'zwan', 'zz']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   7.,   4., ...,   1.,   0.,   1.],\n",
       "       [  4.,  39.,   4., ...,   2.,   3.,   1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15480)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  7.,  4., ...,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all Non-viral Buzzes\n",
    "non_viral_token_count = nb.feature_count_[0, :]\n",
    "non_viral_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,  39.,   4., ...,   2.,   3.,   1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all Viral Buzzes\n",
    "viral_token_count = nb.feature_count_[1, :]\n",
    "viral_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_viral</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>7.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00s</th>\n",
       "      <td>27.0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       non_viral  viral\n",
       "token                  \n",
       "00           0.0    4.0\n",
       "000          7.0   39.0\n",
       "007          4.0    4.0\n",
       "00s         27.0  207.0\n",
       "03           0.0    3.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate non-viral and viral counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'non_viral':non_viral_token_count, 'viral':viral_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_viral</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>realest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creeps</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meredith</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nadu</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unqualified</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep</th>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belgium</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dax</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherquot</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wxyz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reflection</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peyton</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ritchie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dear</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organizer</th>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jimmy</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretzels</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             non_viral  viral\n",
       "token                        \n",
       "realest            1.0    2.0\n",
       "creeps             0.0    2.0\n",
       "meredith           3.0    6.0\n",
       "nz                 0.0    2.0\n",
       "nadu               2.0    3.0\n",
       "unqualified        0.0    1.0\n",
       "deep               4.0   59.0\n",
       "belgium            2.0    0.0\n",
       "dax                4.0    9.0\n",
       "motherquot         1.0    0.0\n",
       "wxyz               0.0    1.0\n",
       "reflection         0.0    2.0\n",
       "peyton             2.0    0.0\n",
       "ritchie            0.0    3.0\n",
       "dear               3.0   16.0\n",
       "ability            1.0    3.0\n",
       "organizer          4.0   17.0\n",
       "jimmy              5.0   50.0\n",
       "closing            0.0    3.0\n",
       "pretzels           1.0    0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(20, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2024.,  8698.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_viral</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>realest</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creeps</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meredith</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nz</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nadu</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          non_viral  viral\n",
       "token                     \n",
       "realest         2.0    3.0\n",
       "creeps          1.0    3.0\n",
       "meredith        4.0    7.0\n",
       "nz              1.0    3.0\n",
       "nadu            3.0    4.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to non-viral and viral counts to avoid dividing by 0\n",
    "tokens['non_viral'] = tokens.non_viral + 1\n",
    "tokens['viral'] = tokens.viral + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_viral</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>realest</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creeps</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meredith</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nz</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nadu</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          non_viral     viral\n",
       "token                        \n",
       "realest    0.000988  0.000345\n",
       "creeps     0.000494  0.000345\n",
       "meredith   0.001976  0.000805\n",
       "nz         0.000494  0.000345\n",
       "nadu       0.001482  0.000460"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the non-viral and viral counts into frequencies\n",
    "tokens['non_viral'] = tokens.non_viral / nb.class_count_[0]\n",
    "tokens['viral'] = tokens.viral / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_viral</th>\n",
       "      <th>viral</th>\n",
       "      <th>viral_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>realest</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.349046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creeps</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.698092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meredith</th>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.407220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nz</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.698092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nadu</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.310263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          non_viral     viral  viral_ratio\n",
       "token                                     \n",
       "realest    0.000988  0.000345     0.349046\n",
       "creeps     0.000494  0.000345     0.698092\n",
       "meredith   0.001976  0.000805     0.407220\n",
       "nz         0.000494  0.000345     0.698092\n",
       "nadu       0.001482  0.000460     0.310263"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of viral-to-non-viral for each token\n",
    "tokens['viral_ratio'] = tokens.viral / tokens.non_viral\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_viral</th>\n",
       "      <th>viral</th>\n",
       "      <th>viral_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stanford</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>28.621752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petty</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>14.892619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gym</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>14.194527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonas</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>11.402161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>10.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>9.307887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>victoria</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>8.609795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hairy</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>8.609795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beckham</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>8.377098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusting</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>8.144401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spray</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>7.911704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anal</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>7.911704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alligator</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>7.911704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spears</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>7.679007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soda</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>7.679007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ups</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>7.679007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judge</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>7.679007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubes</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>7.446309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rob</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>7.213612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cramps</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>7.213612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyebrow</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>7.213612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitty</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>7.213612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diego</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>7.213612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depp</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>6.980915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chip</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>6.980915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rey</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>6.748218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruit</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>6.748218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highlighter</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>6.748218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kendrick</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>6.748218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>con</th>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>6.748218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronunciation</th>\n",
       "      <td>0.012846</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kumar</th>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nigam</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kabali</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mockumentary</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonam</th>\n",
       "      <td>0.013834</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newspaper</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peach</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osborne</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>letters</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starter</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akshay</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonu</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>janitor</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brunswick</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronounce</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snippet</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resting</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum</th>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gort</th>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.025855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dhoni</th>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.025855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cattrall</th>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.025855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kanan</th>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.025855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frappe</th>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.025855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lindsey</th>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.025855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill</th>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.023270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degrassi</th>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.021154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bhatt</th>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stages</th>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hauts</th>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.013688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15480 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               non_viral     viral  viral_ratio\n",
       "token                                          \n",
       "stanford        0.000494  0.014141    28.621752\n",
       "petty           0.000494  0.007358    14.892619\n",
       "gym             0.000494  0.007013    14.194527\n",
       "jonas           0.000494  0.005633    11.402161\n",
       "san             0.000494  0.004944    10.005978\n",
       "yeah            0.000494  0.004599     9.307887\n",
       "victoria        0.000494  0.004254     8.609795\n",
       "hairy           0.000494  0.004254     8.609795\n",
       "beckham         0.000494  0.004139     8.377098\n",
       "disgusting      0.000494  0.004024     8.144401\n",
       "spray           0.000494  0.003909     7.911704\n",
       "anal            0.000494  0.003909     7.911704\n",
       "alligator       0.000494  0.003909     7.911704\n",
       "spears          0.000494  0.003794     7.679007\n",
       "soda            0.000494  0.003794     7.679007\n",
       "1ups            0.000494  0.003794     7.679007\n",
       "judge           0.000494  0.003794     7.679007\n",
       "pubes           0.000494  0.003679     7.446309\n",
       "rob             0.000494  0.003564     7.213612\n",
       "cramps          0.000494  0.003564     7.213612\n",
       "eyebrow         0.000494  0.003564     7.213612\n",
       "kitty           0.000494  0.003564     7.213612\n",
       "diego           0.000494  0.003564     7.213612\n",
       "depp            0.000988  0.006898     6.980915\n",
       "chip            0.000494  0.003449     6.980915\n",
       "rey             0.000494  0.003334     6.748218\n",
       "fruit           0.000988  0.006668     6.748218\n",
       "highlighter     0.000494  0.003334     6.748218\n",
       "kendrick        0.000494  0.003334     6.748218\n",
       "con             0.000988  0.006668     6.748218\n",
       "...                  ...       ...          ...\n",
       "pronunciation   0.012846  0.000460     0.035800\n",
       "kumar           0.006423  0.000230     0.035800\n",
       "nigam           0.003458  0.000115     0.033242\n",
       "kabali          0.003458  0.000115     0.033242\n",
       "mockumentary    0.003458  0.000115     0.033242\n",
       "sonam           0.013834  0.000460     0.033242\n",
       "newspaper       0.003458  0.000115     0.033242\n",
       "peach           0.003458  0.000115     0.033242\n",
       "osborne         0.003458  0.000115     0.033242\n",
       "letters         0.003458  0.000115     0.033242\n",
       "starter         0.003458  0.000115     0.033242\n",
       "akshay          0.003458  0.000115     0.033242\n",
       "sonu            0.003458  0.000115     0.033242\n",
       "janitor         0.003458  0.000115     0.033242\n",
       "brunswick       0.003458  0.000115     0.033242\n",
       "pronounce       0.003458  0.000115     0.033242\n",
       "snippet         0.003458  0.000115     0.033242\n",
       "resting         0.003458  0.000115     0.033242\n",
       "momentum        0.003458  0.000115     0.033242\n",
       "gort            0.004447  0.000115     0.025855\n",
       "dhoni           0.004447  0.000115     0.025855\n",
       "cattrall        0.004447  0.000115     0.025855\n",
       "kanan           0.004447  0.000115     0.025855\n",
       "frappe          0.004447  0.000115     0.025855\n",
       "lindsey         0.004447  0.000115     0.025855\n",
       "gill            0.004941  0.000115     0.023270\n",
       "degrassi        0.005435  0.000115     0.021154\n",
       "bhatt           0.005929  0.000115     0.019391\n",
       "stages          0.005929  0.000115     0.019391\n",
       "hauts           0.008399  0.000115     0.013688\n",
       "\n",
       "[15480 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by viral_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('viral_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3186173066605349"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the viral_ratio for a given token\n",
    "tokens.loc['lol', 'viral_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
